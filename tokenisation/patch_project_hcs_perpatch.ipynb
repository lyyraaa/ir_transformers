{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:07.213744800Z",
     "start_time": "2025-04-08T10:12:07.200194500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3fa5c69dc9bda7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ellipsis, slice(0, 965, None))\n"
     ]
    }
   ],
   "source": [
    "is_local = True # todo\n",
    "\n",
    "# Experiment\n",
    "seed = 0 if is_local else int(sys.argv[-2])\n",
    "torch.manual_seed(seed)\n",
    "image_size = 256\n",
    "\n",
    "# Data: which wavenumbers are even allowed to be considered?\n",
    "wv_start = 0\n",
    "wv_end = 965\n",
    "\n",
    "# Data loading\n",
    "test_set_fraction = 0.2\n",
    "val_set_fraction = 0.2\n",
    "batch_size= 64 # todo\n",
    "patch_dim = 25\n",
    "use_augmentation = True\n",
    "embed_dim=256\n",
    "\n",
    "# Network\n",
    "dropout_p=0.5\n",
    "\n",
    "# Training schedule\n",
    "lr = 5e-4\n",
    "l2 = 5e-2 # 5e-1\n",
    "max_iters = 5000\n",
    "pseudo_epoch = 100\n",
    "\n",
    "# dimensionality reduction parameters\n",
    "r_method = 'linear' # {'linear','pca,'fixed'}\n",
    "reduce_dim = 64 if is_local else int(sys.argv[-1]) # used only for r_method = 'pca' or 'linear'\n",
    "channels_used = np.s_[...,wv_start:wv_end] # used only when r_method = 'fixed'\n",
    "print(channels_used)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:07.278861700Z",
     "start_time": "2025-04-08T10:12:07.211751400Z"
    }
   },
   "id": "222959fcfa561aff",
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 228 cores\n",
      "Using 965/965 wavenumbers\n"
     ]
    }
   ],
   "source": [
    "def csf_fp(filepath):\n",
    "    return filepath.replace('D:/datasets','D:/datasets' if is_local else './')\n",
    "\n",
    "master = pd.read_excel(csf_fp(rf'D:/datasets/pcuk2023_ftir_whole_core/master_sheet.xlsx'))\n",
    "slide = master['slide'].to_numpy()\n",
    "patient_id = master['patient_id'].to_numpy()\n",
    "hdf5_filepaths = np.array([csf_fp(fp) for fp in master['hdf5_filepath']])\n",
    "annotation_filepaths = np.array([csf_fp(fp) for fp in master['annotation_filepath']])\n",
    "mask_filepaths = np.array([csf_fp(fp) for fp in master['mask_filepath']])\n",
    "wavenumbers = np.load(csf_fp(f'D:/datasets/pcuk2023_ftir_whole_core/wavenumbers.npy'))[wv_start:wv_end]\n",
    "wavenumbers_used = wavenumbers[channels_used]\n",
    "\n",
    "seq_len = len(wavenumbers_used) if r_method == 'fixed' else reduce_dim \n",
    "\n",
    "annotation_class_colors = np.array([[0,255,0],[128,0,128],[255,0,255],[0,0,255],[255,165,0],[255,0,0]])\n",
    "annotation_class_names = np.array(['epithelium_n','stroma_n','epithelium_c','stroma_c','corpora_amylacea','blood'])\n",
    "n_classes = len(annotation_class_names)\n",
    "print(f\"Loaded {len(slide)} cores\")\n",
    "print(f\"Using {len(wavenumbers_used)}/{len(wavenumbers)} wavenumbers\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:08.143244600Z",
     "start_time": "2025-04-08T10:12:07.305266400Z"
    }
   },
   "id": "a78af96389a4cd31",
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Datasets, Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaba53c2e93ca461"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients per data split:\n",
      "\tTRAIN: 135\n",
      "\tVAL: 49\n",
      "\tTEST: 44\n"
     ]
    }
   ],
   "source": [
    "unique_pids = np.unique(patient_id)\n",
    "pids_trainval, pids_test, _, _ = train_test_split(\n",
    "    unique_pids, np.zeros_like(unique_pids), test_size=test_set_fraction, random_state=seed)\n",
    "pids_train, pids_val, _, _ = train_test_split(\n",
    "    pids_trainval, np.zeros_like(pids_trainval), test_size=(val_set_fraction/(1-test_set_fraction)), random_state=seed)\n",
    "where_train = np.where(np.isin(patient_id,pids_train))\n",
    "where_val = np.where(np.isin(patient_id,pids_val))\n",
    "where_test = np.where(np.isin(patient_id,pids_test))\n",
    "print(f\"Patients per data split:\\n\\tTRAIN: {len(where_train[0])}\\n\\tVAL: {len(where_val[0])}\\n\\tTEST: {len(where_test[0])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:08.183174100Z",
     "start_time": "2025-04-08T10:12:08.144267600Z"
    }
   },
   "id": "e4655cf38851b265",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:08.184229800Z",
     "start_time": "2025-04-08T10:12:08.172454900Z"
    }
   },
   "id": "cf67b857cfc18a80",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ftir_patching_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,hdf5_filepaths, mask_filepaths, annotation_filepaths, channels_use, hcs_min=1, hcs_max=len(wavenumbers_used),\n",
    "                 patch_dim=25, augment=True,):\n",
    "        \n",
    "        # Define data paths\n",
    "        self.hdf5_filepaths = hdf5_filepaths\n",
    "        self.mask_filepaths = mask_filepaths\n",
    "        self.annotation_filepaths = annotation_filepaths\n",
    "        self.augment = augment\n",
    "        \n",
    "        # patch dimensions\n",
    "        self.patch_dim = patch_dim\n",
    "        self.patch_minus = patch_dim //2; self.patch_plus = 1 + (patch_dim // 2)\n",
    "        self.channels = channels_use\n",
    "        self.hcs_min = hcs_min\n",
    "        self.hcs_max = hcs_max\n",
    "        \n",
    "        # class data\n",
    "        self.annotation_class_colors = annotation_class_colors\n",
    "        self.annotation_class_names = annotation_class_names\n",
    "        self.total_sampled = torch.zeros(len(self.annotation_class_colors))\n",
    "        \n",
    "        # define data augmentation pipeline\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomVerticalFlip(p=0.5),\n",
    "        ])\n",
    "        \n",
    "        # Open every core hdf5 file\n",
    "        self.open()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_pixels\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # get patch data\n",
    "        row = self.rows[idx]\n",
    "        col = self.cols[idx]\n",
    "        cidx = self.cidxs[idx]\n",
    "        label = self.tissue_classes[idx]\n",
    "        self.total_sampled[label] += 1\n",
    "        \n",
    "        # Are dimensions of patch okay\n",
    "        idx_u = row - self.patch_minus\n",
    "        idx_d = row + self.patch_plus\n",
    "        idx_l = col - self.patch_minus\n",
    "        idx_r = col + self.patch_plus\n",
    "        pad_u = max(-idx_u,0); idx_u = max(idx_u,0)\n",
    "        pad_d = max(idx_d-image_size,0); idx_d = min(idx_d,image_size)\n",
    "        pad_l = max(-idx_l,0); idx_l = max(idx_l,0)\n",
    "        pad_r = max(idx_r-image_size,0); idx_r = min(idx_r,image_size)\n",
    "        \n",
    "        # get patch\n",
    "        patch = torch.from_numpy(\n",
    "            self.hdf5_files[cidx]['spectra'][idx_u:idx_d,idx_l:idx_r,*self.channels],\n",
    "        ).permute(2,0,1)\n",
    "        patch *= torch.from_numpy(\n",
    "            self.hdf5_files[cidx]['mask'][idx_u:idx_d,idx_l:idx_r,],\n",
    "        ).unsqueeze(0)\n",
    "        \n",
    "        # pad patch\n",
    "        patch = torch.nn.functional.pad(patch,(pad_l,pad_r,pad_u,pad_d,0,0))\n",
    "        \n",
    "        if self.augment:\n",
    "            patch = self.transforms(patch)\n",
    "        return patch,label\n",
    "\n",
    "    # split annotations from H x W x 3 to C x H x W, one/zerohot along C dimension\n",
    "    def split_annotations(self,annotations_img):\n",
    "        split = torch.zeros((len(self.annotation_class_colors),*annotations_img.shape[:-1]))\n",
    "        for c,col in enumerate(annotation_class_colors):\n",
    "            split[c,:,:] = torch.from_numpy(np.all(annotations_img == self.annotation_class_colors[c],axis=-1)) \n",
    "        return split\n",
    "    \n",
    "    # open every file \n",
    "    def open(self):\n",
    "        self.hdf5_files = []\n",
    "        self.tissue_classes = []\n",
    "        self.rows = []\n",
    "        self.cols = []\n",
    "        self.cidxs = []\n",
    "        \n",
    "        # for every core in dataset,\n",
    "        for cidx in range(0,len(self.hdf5_filepaths)):\n",
    "            # open annotations and remove edges and non-tissue px\n",
    "            annotation = self.split_annotations(cv2.imread(self.annotation_filepaths[cidx])[:,:,::-1])\n",
    "            mask = torch.from_numpy(cv2.imread(self.mask_filepaths[cidx])[:,:,1]) / 255\n",
    "            annotation *= mask\n",
    "            # for every class,\n",
    "            for cls in range(len(annotation_class_names)):\n",
    "                # get location of annotations, append to lists\n",
    "                r,c = torch.where(annotation[cls])\n",
    "                num_cls = annotation[cls].sum().int().item()\n",
    "                self.tissue_classes.extend([cls,]*num_cls)\n",
    "                self.cidxs.extend([cidx,]*num_cls)\n",
    "                self.rows.extend(r)\n",
    "                self.cols.extend(c)\n",
    "            # add open hdf5 file to list\n",
    "            self.hdf5_files.append(h5py.File(self.hdf5_filepaths[cidx],'r'))\n",
    "                \n",
    "        # construct data tensors\n",
    "        self.rows = torch.Tensor(self.rows).int()\n",
    "        self.cols = torch.Tensor(self.cols).int()\n",
    "        self.tissue_classes = torch.Tensor(self.tissue_classes).long()\n",
    "        self.cidxs = torch.Tensor(self.cidxs).int()\n",
    "        self.total_pixels = len(self.cidxs)\n",
    "\n",
    "    # close every open hdf5 file\n",
    "    def close(self):\n",
    "        for cidx in range(len(self.hdf5_files)):\n",
    "            self.hdf5_files[cidx].close()\n",
    "        self.hdf5_files = []\n",
    "        self.tissue_classes = []\n",
    "        self.xs = []\n",
    "        self.ys = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:08.216811700Z",
     "start_time": "2025-04-08T10:12:08.176051800Z"
    }
   },
   "id": "a8a3aa59fbf57012",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader sizes:\n",
      "\ttrain: 5992\n",
      "\tval: 2013\n",
      "\ttest: 1793\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_train], mask_filepaths[where_train], annotation_filepaths[where_train], channels_used,\n",
    "    patch_dim = patch_dim, augment=use_augmentation,\n",
    ")\n",
    "dataset_val = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_val], mask_filepaths[where_val], annotation_filepaths[where_val], channels_used,\n",
    "    patch_dim = patch_dim, augment=False,\n",
    ")\n",
    "dataset_test = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_test], mask_filepaths[where_test], annotation_filepaths[where_test], channels_used,\n",
    "    patch_dim = patch_dim, augment=False,\n",
    ")\n",
    "\n",
    "# Instiantiate data loaders\n",
    "_, class_counts = np.unique(dataset_train.tissue_classes, return_counts=True)\n",
    "class_weights = 1 / class_counts\n",
    "class_weights = class_weights[dataset_train.tissue_classes]\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(class_weights, len(class_weights), replacement=True)\n",
    "\n",
    "_, class_counts = np.unique(dataset_val.tissue_classes, return_counts=True)\n",
    "class_weights = 1 / class_counts\n",
    "class_weights = class_weights[dataset_val.tissue_classes]\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(class_weights, len(class_weights), replacement=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=train_sampler,drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, sampler=val_sampler,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "print(f\"loader sizes:\\n\\ttrain: {len(train_loader)}\\n\\tval: {len(val_loader)}\\n\\ttest: {len(test_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.490264900Z",
     "start_time": "2025-04-08T10:12:08.220827400Z"
    }
   },
   "id": "c6bebd9eeed34711",
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define dimensionality reduction method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdcc80122d23428"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LinearReduction(nn.Module):\n",
    "    def __init__(self,input_dim,reduce_dim):\n",
    "        super().__init__()\n",
    "        self.reduce_dim = reduce_dim\n",
    "        self.input_norm = nn.BatchNorm2d(input_dim)\n",
    "        self.projection = nn.Conv2d(input_dim,reduce_dim,kernel_size=1,stride=1) # todo bias = false?\n",
    "        self.projection_norm = nn.BatchNorm2d(reduce_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.projection_norm(self.projection(self.input_norm(x)))\n",
    "    \n",
    "class PCAReduce(nn.Module): # todo need to add batchnorm here too?\n",
    "    def __init__(self,reduce_dim,means,loadings):\n",
    "        super().__init__()\n",
    "        self.reduce_dim = reduce_dim\n",
    "        self.register_buffer('means', torch.from_numpy(means).float().reshape(1,-1,1,1))\n",
    "        self.register_buffer('loadings', torch.from_numpy(loadings).float())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        projected = x - self.means\n",
    "        \n",
    "        b,c,h,w = projected.shape\n",
    "        projected = projected.permute(0,2,3,1).reshape(b,h*w,c)\n",
    "        projected = torch.matmul(projected, self.loadings.T)\n",
    "        projected = projected.reshape(b,h,w,self.reduce_dim).permute(0,3,1,2)\n",
    "        \n",
    "        return projected\n",
    "        \n",
    "class FixedReduction(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.input_norm = nn.BatchNorm2d(input_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.input_norm(x)\n",
    "\n",
    "if r_method == 'pca':\n",
    "    spectral_sample = []\n",
    "    batch_samples = 0\n",
    "    for data,label in train_loader:\n",
    "        spectral_sample.append(data[...,patch_dim//2,patch_dim//2].numpy())\n",
    "        batch_samples += 1\n",
    "        if batch_samples > 10000//batch_size: break\n",
    "    spectral_sample = np.concatenate(spectral_sample,axis=0)\n",
    "    spectral_means = np.mean(spectral_sample,axis=0)\n",
    "    spectral_sample -= spectral_means\n",
    "    pca = PCA(n_components=reduce_dim)\n",
    "    pca.fit(spectral_sample)\n",
    "    spectral_loadings = pca.components_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.498357200Z",
     "start_time": "2025-04-08T10:12:30.497298500Z"
    }
   },
   "id": "e49ecda26ba39e97",
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f550708e9f4c74c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LearnablePositionEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.0, sequence_length: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.pe = nn.Parameter(torch.tensor(np.random.normal(loc=0.0, scale=0.02, size=(1, sequence_length, d_model)),dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe\n",
    "        \n",
    "        if self.training:\n",
    "            x = x * (torch.rand((x.size(0),x.size(1),1)) > (torch.rand((1,)) - 0.2)) # 0.2 here means that a minimum of 20% of channels will be non-zero #todo reconsider \n",
    "        \n",
    "        return x\n",
    "\n",
    "class patch25_transformer(nn.Module):\n",
    "    def __init__(self,input_dim,reduce_dim,n_classes,embed_dim):\n",
    "        super().__init__()\n",
    "        # input processing and dimensionality reduction\n",
    "        if r_method == 'pca':\n",
    "            self.input_processing = PCAReduce(reduce_dim,spectral_means,spectral_loadings)\n",
    "        elif r_method == 'fixed':\n",
    "            self.input_processing = FixedReduction(input_dim)\n",
    "        elif r_method == 'linear':\n",
    "            self.input_processing = LinearReduction(input_dim,reduce_dim)\n",
    "            \n",
    "        self.d_model = embed_dim\n",
    "        self.cls_token = nn.Parameter(torch.normal(torch.zeros((1,1,self.d_model)),0.02))\n",
    "            \n",
    "        self.patch_project = nn.Conv3d(\n",
    "                1,\n",
    "                embed_dim,\n",
    "                kernel_size=(1,patch_dim,patch_dim),\n",
    "        )\n",
    "            \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=16,\n",
    "            dim_feedforward=256,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True)\n",
    "        self.encoder_stack = nn.TransformerEncoder(\n",
    "            encoder_layer=self.encoder_layer,\n",
    "            num_layers=6)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.d_model,n_classes),\n",
    "        )\n",
    "        \n",
    "        self.pe = LearnablePositionEncoding(\n",
    "            d_model=self.d_model,\n",
    "            dropout=0,\n",
    "            sequence_length=seq_len + 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_processing(x)\n",
    "        \n",
    "        \n",
    "        x = self.patch_project(x.unsqueeze(1)) # X -> B x 1 x C x H x W -> B x K x C x 1 x 1 -> \n",
    "        x = x.squeeze().permute(0,2,1) # X -> B x C x K\n",
    "        x = torch.cat([self.cls_token.expand(x.shape[0],-1,-1),x],dim=1)\n",
    "        x_pe = self.pe(x)\n",
    "        x_tr = self.encoder_stack(x_pe)\n",
    "        logits = self.classifier(x_tr[:, 0])\n",
    "        return logits\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.508428400Z",
     "start_time": "2025-04-08T10:12:30.500380300Z"
    }
   },
   "id": "33535f38f1458959",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_model with 3.013M params composed of:\n"
     ]
    }
   ],
   "source": [
    "model = patch25_transformer(\n",
    "    input_dim=len(wavenumbers_used),\n",
    "    reduce_dim=len(wavenumbers_used) if r_method == 'fixed' else reduce_dim,\n",
    "    n_classes=n_classes,\n",
    "    embed_dim=embed_dim,\n",
    ")\n",
    "\n",
    "print(f\"fusion_model with {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f}M params composed of:\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.637108500Z",
     "start_time": "2025-04-08T10:12:30.514555400Z"
    }
   },
   "id": "a10ccd9a5ba9b9e9",
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dfdaf2ad556fa46"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=l2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=500, threshold=0.01, cooldown=250)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.686014700Z",
     "start_time": "2025-04-08T10:12:30.640123700Z"
    }
   },
   "id": "50a59f2ddf1e3f0d",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_losses,validation_losses = [],[]\n",
    "training_accs,validation_accs = [],[]\n",
    "training_f1ms,validation_f1ms = [],[]\n",
    "training_f1s,validation_f1s = [],[]\n",
    "lr_decreases = []\n",
    "current_iters = 0\n",
    "best_val_f1 = 0\n",
    "best_val_iter = 0\n",
    "stop_training=False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:12:30.690136400Z",
     "start_time": "2025-04-08T10:12:30.686014700Z"
    }
   },
   "id": "51f82808428ba870",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON ITER: 0, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 2.016 | OA: 0.2188 | F1M: 0.1910\n",
      "VAL ----- | Loss: 2.007 | OA: 0.2031 | F1M: 0.0563\n",
      "ON ITER: 100, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 1.131 | OA: 0.4967 | F1M: 0.4629\n",
      "VAL ----- | Loss: 2.337 | OA: 0.2459 | F1M: 0.1445\n",
      "ON ITER: 200, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.8988 | OA: 0.6178 | F1M: 0.5864\n",
      "VAL ----- | Loss: 0.9103 | OA: 0.6262 | F1M: 0.5901\n",
      "ON ITER: 300, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.7575 | OA: 0.7022 | F1M: 0.6844\n",
      "VAL ----- | Loss: 0.8709 | OA: 0.6784 | F1M: 0.6643\n",
      "ON ITER: 400, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.6443 | OA: 0.7416 | F1M: 0.7257\n",
      "VAL ----- | Loss: 0.754 | OA: 0.6992 | F1M: 0.6921\n",
      "ON ITER: 500, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.6233 | OA: 0.7553 | F1M: 0.7424\n",
      "VAL ----- | Loss: 0.7153 | OA: 0.7236 | F1M: 0.7147\n",
      "ON ITER: 600, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.6072 | OA: 0.7512 | F1M: 0.7438\n",
      "VAL ----- | Loss: 0.6885 | OA: 0.725 | F1M: 0.7132\n",
      "ON ITER: 700, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.5984 | OA: 0.7614 | F1M: 0.7490\n",
      "VAL ----- | Loss: 0.6828 | OA: 0.7306 | F1M: 0.7180\n",
      "ON ITER: 800, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.5721 | OA: 0.7686 | F1M: 0.7551\n",
      "VAL ----- | Loss: 0.6747 | OA: 0.7367 | F1M: 0.7236\n",
      "ON ITER: 900, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.5847 | OA: 0.7661 | F1M: 0.7575\n",
      "VAL ----- | Loss: 0.6508 | OA: 0.7452 | F1M: 0.7363\n",
      "ON ITER: 1000, metrics for last 100 iters:\n",
      "TRAIN --- | Loss: 0.5851 | OA: 0.7636 | F1M: 0.7501\n",
      "VAL ----- | Loss: 0.6797 | OA: 0.7341 | F1M: 0.7239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[120], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 8\u001B[0m out \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(out, label)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[116], line 66\u001B[0m, in \u001B[0;36mpatch25_transformer.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     64\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls_token\u001B[38;5;241m.\u001B[39mexpand(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m),x],dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     65\u001B[0m x_pe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpe(x)\n\u001B[1;32m---> 66\u001B[0m x_tr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_stack(x_pe)\n\u001B[0;32m     67\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(x_tr[:, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m logits\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:511\u001B[0m, in \u001B[0;36mTransformerEncoder.forward\u001B[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    508\u001B[0m is_causal \u001B[38;5;241m=\u001B[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001B[0;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m--> 511\u001B[0m     output \u001B[38;5;241m=\u001B[39m mod(\n\u001B[0;32m    512\u001B[0m         output,\n\u001B[0;32m    513\u001B[0m         src_mask\u001B[38;5;241m=\u001B[39mmask,\n\u001B[0;32m    514\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m    515\u001B[0m         src_key_padding_mask\u001B[38;5;241m=\u001B[39msrc_key_padding_mask_for_layers,\n\u001B[0;32m    516\u001B[0m     )\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_nested:\n\u001B[0;32m    519\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_padded_tensor(\u001B[38;5;241m0.0\u001B[39m, src\u001B[38;5;241m.\u001B[39msize())\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:904\u001B[0m, in \u001B[0;36mTransformerEncoderLayer.forward\u001B[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    900\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x))\n\u001B[0;32m    901\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    902\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(\n\u001B[0;32m    903\u001B[0m         x\n\u001B[1;32m--> 904\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001B[38;5;241m=\u001B[39mis_causal)\n\u001B[0;32m    905\u001B[0m     )\n\u001B[0;32m    906\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(x))\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:918\u001B[0m, in \u001B[0;36mTransformerEncoderLayer._sa_block\u001B[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    911\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sa_block\u001B[39m(\n\u001B[0;32m    912\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    913\u001B[0m     x: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    916\u001B[0m     is_causal: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    917\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 918\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn(\n\u001B[0;32m    919\u001B[0m         x,\n\u001B[0;32m    920\u001B[0m         x,\n\u001B[0;32m    921\u001B[0m         x,\n\u001B[0;32m    922\u001B[0m         attn_mask\u001B[38;5;241m=\u001B[39mattn_mask,\n\u001B[0;32m    923\u001B[0m         key_padding_mask\u001B[38;5;241m=\u001B[39mkey_padding_mask,\n\u001B[0;32m    924\u001B[0m         need_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    925\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m    926\u001B[0m     )[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    927\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001B[0m, in \u001B[0;36mMultiheadAttention.forward\u001B[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   1342\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmulti_head_attention_forward(\n\u001B[0;32m   1343\u001B[0m         query,\n\u001B[0;32m   1344\u001B[0m         key,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1365\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m   1366\u001B[0m     )\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1368\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmulti_head_attention_forward(\n\u001B[0;32m   1369\u001B[0m         query,\n\u001B[0;32m   1370\u001B[0m         key,\n\u001B[0;32m   1371\u001B[0m         value,\n\u001B[0;32m   1372\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_dim,\n\u001B[0;32m   1373\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\n\u001B[0;32m   1374\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_weight,\n\u001B[0;32m   1375\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_bias,\n\u001B[0;32m   1376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_k,\n\u001B[0;32m   1377\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_v,\n\u001B[0;32m   1378\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_zero_attn,\n\u001B[0;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout,\n\u001B[0;32m   1380\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_proj\u001B[38;5;241m.\u001B[39mweight,\n\u001B[0;32m   1381\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_proj\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m   1382\u001B[0m         training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining,\n\u001B[0;32m   1383\u001B[0m         key_padding_mask\u001B[38;5;241m=\u001B[39mkey_padding_mask,\n\u001B[0;32m   1384\u001B[0m         need_weights\u001B[38;5;241m=\u001B[39mneed_weights,\n\u001B[0;32m   1385\u001B[0m         attn_mask\u001B[38;5;241m=\u001B[39mattn_mask,\n\u001B[0;32m   1386\u001B[0m         average_attn_weights\u001B[38;5;241m=\u001B[39maverage_attn_weights,\n\u001B[0;32m   1387\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m   1388\u001B[0m     )\n\u001B[0;32m   1389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;129;01mand\u001B[39;00m is_batched:\n\u001B[0;32m   1390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m), attn_output_weights\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\torch\\nn\\functional.py:6282\u001B[0m, in \u001B[0;36mmulti_head_attention_forward\u001B[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   6276\u001B[0m v \u001B[38;5;241m=\u001B[39m v\u001B[38;5;241m.\u001B[39mview(bsz, num_heads, src_len, head_dim)\n\u001B[0;32m   6278\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m scaled_dot_product_attention(\n\u001B[0;32m   6279\u001B[0m     q, k, v, attn_mask, dropout_p, is_causal\n\u001B[0;32m   6280\u001B[0m )\n\u001B[0;32m   6281\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m-> 6282\u001B[0m     attn_output\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\u001B[38;5;241m.\u001B[39mview(bsz \u001B[38;5;241m*\u001B[39m tgt_len, embed_dim)\n\u001B[0;32m   6283\u001B[0m )\n\u001B[0;32m   6285\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001B[0;32m   6286\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mview(tgt_len, bsz, attn_output\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "while current_iters < max_iters:\n",
    "    for (bidx, (data, label)) in enumerate(train_loader):\n",
    "        data = data.to(device); label = label.to(device)\n",
    "        \n",
    "        # Push through model\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append log arrays\n",
    "        training_losses.append(loss.item())\n",
    "        pred = out.argmax(dim=1).detach().cpu().numpy()\n",
    "        actual = label.cpu().numpy()\n",
    "        training_accs.append(accuracy_score(actual,pred))\n",
    "        training_f1ms.append(f1_score(actual, pred, average='macro'))\n",
    "        training_f1s.append(f1_score(actual, pred, average=None, labels=np.arange(0,n_classes),zero_division=0))\n",
    "        \n",
    "        # Do validation cycle\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # load data\n",
    "            data, label = next(iter(val_loader))\n",
    "            data = data.to(device); label = label.to(device)\n",
    "            \n",
    "            # Push through model\n",
    "            out = model(data)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_fn(out, label)\n",
    "            \n",
    "            # Append log arrays\n",
    "            validation_losses.append(loss.item())\n",
    "            pred = out.argmax(dim=1).detach().cpu().numpy()\n",
    "            actual = label.cpu().numpy()\n",
    "            validation_accs.append(accuracy_score(actual,pred))\n",
    "            validation_f1ms.append(f1_score(actual, pred, average='macro'))\n",
    "            validation_f1s.append(f1_score(actual, pred, average=None, labels=np.arange(0,n_classes),zero_division=0))\n",
    "        \n",
    "        # Print training statistics every N iters\n",
    "        if current_iters % pseudo_epoch == 0:\n",
    "            print(f\"ON ITER: {current_iters}, metrics for last {pseudo_epoch} iters:\")\n",
    "            print(f\"TRAIN --- | Loss: {np.mean(training_losses[-pseudo_epoch:]):.4} | OA: {np.mean(training_accs[-pseudo_epoch:]):.4} | F1M: {np.mean(training_f1ms[-pseudo_epoch:]):.4f}\")\n",
    "            print(f\"VAL ----- | Loss: {np.mean(validation_losses[-pseudo_epoch:]):.4} | OA: {np.mean(validation_accs[-pseudo_epoch:]):.4} | F1M: {np.mean(validation_f1ms[-pseudo_epoch:]):.4f}\")\n",
    "        \n",
    "        # If performance on validation set best so far, save model\n",
    "        if np.mean(validation_f1ms[-pseudo_epoch:]) > best_val_f1:\n",
    "            best_val_f1 = np.mean(validation_f1ms[-pseudo_epoch:])\n",
    "            best_val_iter = current_iters\n",
    "            if not is_local:\n",
    "                torch.save(model.state_dict(), rf'./model_weights_{seed}.pt')\n",
    "        \n",
    "        # Step the scheduler based on the validation set performance\n",
    "        current_iters += 1\n",
    "        if current_iters > max_iters: \n",
    "            stop_training = True\n",
    "            break\n",
    "        if current_iters > pseudo_epoch:\n",
    "            scheduler.step(np.mean(validation_f1ms[-pseudo_epoch:]))\n",
    "            new_lr = optimizer.param_groups[0]['lr']\n",
    "            if new_lr != lr:\n",
    "                print(f\"Val f1 plateaued, lr {lr} -> {new_lr}\")\n",
    "                lr = new_lr\n",
    "                lr_decreases.append(current_iters)\n",
    "                if len(lr_decreases) >= 2: \n",
    "                    stop_training = True\n",
    "                    print(\"Val f1 decreased twice, ending training early\")\n",
    "                    break\n",
    "    if stop_training: break\n",
    "\n",
    "training_losses = np.array(training_losses); validation_losses = np.array(validation_losses)\n",
    "training_accs = np.array(training_accs); validation_accs = np.array(validation_accs)\n",
    "training_f1ms = np.array(training_f1ms); validation_f1ms = np.array(validation_f1ms)\n",
    "training_f1s = np.stack(training_f1s,axis=0); validation_f1s = np.stack(validation_f1s,axis=0)\n",
    "print(f\"Training complete after {current_iters} iterations\\n\\ttotal samples       :    {current_iters*batch_size}\\n\\t -=-=-=-=-=-=-=-=-=-=-=-=-=-\")\n",
    "for cls_idx, samples_loaded in enumerate(dataset_train.total_sampled.numpy()):\n",
    "    print(f\"\\t{annotation_class_names[cls_idx]}{(20-len(annotation_class_names[cls_idx])) * ' '}:    {int(samples_loaded)}\")\n",
    "print(f\"Metrics for final {pseudo_epoch} iterations:\")\n",
    "print(f\"TRAIN --- | Loss: {training_losses[-pseudo_epoch:].mean():.4f} | OA: {training_accs[-pseudo_epoch:].mean():.4f} | f1: {training_f1ms[-pseudo_epoch:].mean():.4f}\")\n",
    "print(f\"VAL ----- | Loss: {validation_losses[-pseudo_epoch:].mean():.4f} | OA: {validation_accs[-pseudo_epoch:].mean():.4f} | f1: {validation_f1ms[-pseudo_epoch:].mean():.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.467790500Z",
     "start_time": "2025-04-08T10:12:30.699267900Z"
    }
   },
   "id": "7c6adbd14fd799f6",
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "307cf693fb06cb7e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on entire testing set:\n",
      "TEST ---- | Loss: 0.7594 | OA: 0.6661 | f1: 0.7009\n",
      "epithelium_n         : 0.6562\n",
      "stroma_n             : 0.6844\n",
      "epithelium_c         : 0.7424\n",
      "stroma_c             : 0.4571\n",
      "corpora_amylacea     : 0.9105\n",
      "blood                : 0.7544\n",
      "Total samples loaded for each class during TESTING\n",
      "epithelium_n        :    19909\n",
      "stroma_n            :    25624\n",
      "epithelium_c        :    44074\n",
      "stroma_c            :    21470\n",
      "corpora_amylacea    :    2147\n",
      "blood               :    1528\n"
     ]
    }
   ],
   "source": [
    "running_loss_test = 0\n",
    "test_preds, test_targets = [], []\n",
    "\n",
    "if not is_local:\n",
    "    model.load_state_dict(torch.load(rf'./model_weights_{seed}.pt', weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        print(f\"Iter: {batch_idx}/{len(test_loader)}\",end=\"\\r\")        \n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Push through model\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, label)\n",
    "\n",
    "        # Calculate metrics\n",
    "        running_loss_test += loss.cpu().item() \n",
    "        pred = out.argmax(dim=1).detach().cpu().numpy()\n",
    "        actual = label.cpu().numpy()\n",
    "        test_preds.extend(pred)\n",
    "        test_targets.extend(actual)\n",
    "\n",
    "test_targets = np.array(test_targets); test_preds = np.array(test_preds)\n",
    "test_loss = running_loss_test / batch_idx\n",
    "test_acc = accuracy_score(test_targets, test_preds)\n",
    "test_f1m = f1_score(test_targets, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_targets, test_preds, average=None)\n",
    "\n",
    "print(\"Metrics on entire testing set:\")\n",
    "print(f\"TEST ---- | Loss: {test_loss:.4f} | OA: {test_acc:.4f} | f1: {test_f1m:.4f}\")\n",
    "for cls_idx, f1 in enumerate(test_f1):\n",
    "    print(f\"{annotation_class_names[cls_idx]}{(20 - len(annotation_class_names[cls_idx])) * ' '} : {f1:.4f}\")\n",
    "print(\"Total samples loaded for each class during TESTING\")\n",
    "for cls_idx, samples_loaded in enumerate(dataset_test.total_sampled.numpy()):\n",
    "    print(f\"{annotation_class_names[cls_idx]}{(20-len(annotation_class_names[cls_idx])) * ' '}:    {int(samples_loaded)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T11:07:35.243262500Z",
     "start_time": "2025-04-08T10:55:47.572393600Z"
    }
   },
   "id": "242a34c1a6fe3be8",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "locarray = np.zeros((seq_len,seq_len))\n",
    "cos = nn.CosineSimilarity(dim=0)\n",
    "for r in range(seq_len):\n",
    "    for c in range(seq_len):\n",
    "        locarray[r,c] = cos(model.pe.pe[0][r + 1],model.pe.pe[0][c + 1]).detach().cpu().numpy()\n",
    "fig.suptitle(\"Cosine similarity of position embeddings\")\n",
    "ax.matshow(locarray)\n",
    "fig.tight_layout()\n",
    "if not is_local:\n",
    "    plt.savefig(f'./position_embedding_{seed}.png'); plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.471040400Z",
     "start_time": "2025-04-08T10:55:28.470010500Z"
    }
   },
   "id": "88f9ba9a718fd48c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67ff17a2ebecf4ae"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[121], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m ax[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(moving_average(validation_losses,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))),moving_average(validation_losses,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m,color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124morange\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m ax[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(moving_average(validation_losses,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m))),moving_average(validation_losses,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m),alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124morange\u001B[39m\u001B[38;5;124m'\u001B[39m,label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m ax[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mscatter(current_iters,test_loss,color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgreen\u001B[39m\u001B[38;5;124m'\u001B[39m,label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m,marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m ax[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mset_title(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss\u001B[39m\u001B[38;5;124m\"\u001B[39m); ax[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[0;32m     15\u001B[0m ax[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(moving_average(training_accs,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))),moving_average(training_accs,n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m,color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcornflowerblue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_loss' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x500 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def moving_average(a, n=3): # https://stackoverflow.com/questions/14313510/how-to-calculate-rolling-moving-average-using-python-numpy-scipy\n",
    "    a = np.pad(a, ((n-1)//2,(n-1)//2 + ((n-1) % 2)), mode='edge')\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,5))\n",
    "ax[0].plot(np.arange(0,len(moving_average(training_losses,n=1))),moving_average(training_losses,n=1),alpha=0.3,color='cornflowerblue')\n",
    "ax[0].plot(np.arange(0,len(moving_average(training_losses,n=50))),moving_average(training_losses,n=50),alpha=1,color='cornflowerblue',label=\"train\")\n",
    "ax[0].plot(np.arange(0,len(moving_average(validation_losses,n=1))),moving_average(validation_losses,n=1),alpha=0.3,color='orange')\n",
    "ax[0].plot(np.arange(0,len(moving_average(validation_losses,n=50))),moving_average(validation_losses,n=50),alpha=1,color='orange',label=\"validation\")\n",
    "ax[0].scatter(current_iters,test_loss,color='green',label=\"test\",marker=\"x\")\n",
    "ax[0].set_title(\"Loss\"); ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(0,len(moving_average(training_accs,n=1))),moving_average(training_accs,n=1),alpha=0.3,color='cornflowerblue')\n",
    "ax[1].plot(np.arange(0,len(moving_average(training_accs,n=50))),moving_average(training_accs,n=50),alpha=1,color='cornflowerblue',label=\"train\")\n",
    "ax[1].plot(np.arange(0,len(moving_average(validation_accs,n=1))),moving_average(validation_accs,n=1),alpha=0.3,color='orange')\n",
    "ax[1].plot(np.arange(0,len(moving_average(validation_accs,n=50))),moving_average(validation_accs,n=50),alpha=1,color='orange',label=\"validation\")\n",
    "ax[1].scatter(current_iters,test_acc,color='green',label=\"test\",marker=\"x\")\n",
    "ax[1].set_title(\"Accuracy\"); ax[1].legend()\n",
    "\n",
    "ax[2].plot(np.arange(0,len(moving_average(training_f1ms,n=1))),moving_average(training_f1ms,n=1),alpha=0.3,color='cornflowerblue')\n",
    "ax[2].plot(np.arange(0,len(moving_average(training_f1ms,n=50))),moving_average(training_f1ms,n=50),alpha=1,color='cornflowerblue',label=\"train\")\n",
    "ax[2].plot(np.arange(0,len(moving_average(validation_f1ms,n=1))),moving_average(validation_f1ms,n=1),alpha=0.3,color='orange')\n",
    "ax[2].plot(np.arange(0,len(moving_average(validation_f1ms,n=50))),moving_average(validation_f1ms,n=50),alpha=1,color='orange',label=\"validation\")\n",
    "ax[2].scatter(current_iters,test_f1m,color='green',label=\"test\",marker=\"x\")\n",
    "ax[2].set_title(\"Macro F1 Score\"); ax[2].legend()\n",
    "\n",
    "ax[0].axvline(x=best_val_iter, ymin=0, ymax=1, color='red',alpha=0.3)\n",
    "ax[1].axvline(x=best_val_iter, ymin=0, ymax=1, color='red',alpha=0.3)\n",
    "ax[2].axvline(x=best_val_iter, ymin=0, ymax=1, color='red',alpha=0.3)\n",
    "\n",
    "for lrd in lr_decreases:\n",
    "    ax[0].axvline(x=lrd, ymin=0, ymax=1, color='grey',alpha=0.3)\n",
    "    ax[1].axvline(x=lrd, ymin=0, ymax=1, color='grey',alpha=0.3)\n",
    "    ax[2].axvline(x=lrd, ymin=0, ymax=1, color='grey',alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "if not is_local:\n",
    "    plt.savefig(f'./loss_curve_{seed}.png'); plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:37.107460200Z",
     "start_time": "2025-04-08T10:55:36.880848700Z"
    }
   },
   "id": "5aa6f4abb81d43a8",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_f1s = np.stack(training_f1s,axis=0)\n",
    "validation_f1s = np.stack(validation_f1s,axis=0)\n",
    "fig,ax = plt.subplots(2,3,figsize=(15,5)); ax = ax.flatten()\n",
    "for cls in range(n_classes):\n",
    "    ax[cls].plot(np.arange(0,len(moving_average(training_f1s[:,cls],n=1))),moving_average(training_f1s[:,cls],n=1),alpha=0.3,color='k')\n",
    "    ax[cls].plot(np.arange(0,len(moving_average(training_f1s[:,cls],n=50))),moving_average(training_f1s[:,cls],n=50),alpha=1,color='k',label=\"train\")\n",
    "    ax[cls].plot(np.arange(0,len(moving_average(validation_f1s[:,cls],n=1))),moving_average(validation_f1s[:,cls],n=1),alpha=0.3,color=annotation_class_colors[cls]/255)\n",
    "    ax[cls].plot(np.arange(0,len(moving_average(validation_f1s[:,cls],n=50))),moving_average(validation_f1s[:,cls],n=50),alpha=1,color=annotation_class_colors[cls]/255, label=\"validation\")\n",
    "    ax[cls].scatter(current_iters,test_f1[cls],color=annotation_class_colors[cls]/255,label=\"test\",marker=\"x\")\n",
    "    ax[cls].set_ylim(ymin=0,ymax=1)\n",
    "    for lrd in lr_decreases:\n",
    "        ax[cls].axvline(x=lrd, ymin=0, ymax=1, color='grey',alpha=0.5)\n",
    "    ax[cls].axvline(x=best_val_iter, ymin=0, ymax=1, color='red',alpha=0.3)\n",
    "fig.suptitle(\"Class-specific F1 scores\")\n",
    "plt.tight_layout()\n",
    "if not is_local:\n",
    "    plt.savefig(f'./loss_curve_individual_{seed}.png'); plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.474066Z",
     "start_time": "2025-04-08T10:55:28.473069100Z"
    }
   },
   "id": "60c4c1d2914ee636",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finish experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd7e4042615b52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not is_local:\n",
    "    model = model.cpu()\n",
    "    torch.save(model.state_dict(), rf'./model_weights_{seed}.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.475094100Z",
     "start_time": "2025-04-08T10:55:28.474066Z"
    }
   },
   "id": "b8248f10250d5d36",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read existing results file\n",
    "if not is_local:\n",
    "    if os.path.isfile('results.txt'):\n",
    "        f = open('results.txt','r')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    else: \n",
    "        lines = [x+', \\n' for x in['seed',*annotation_class_names,'overall_acc','macro_f1']]\n",
    "        \n",
    "    # Process files\n",
    "    lines[0] = lines[0].replace('\\n',str(seed) + ', \\n')\n",
    "    for cls in range(n_classes):\n",
    "        lines[cls+1] = lines[cls+1].replace('\\n',str(test_f1[cls]) + ', \\n' )\n",
    "    lines[n_classes+1] = lines[n_classes+1].replace('\\n',str(test_acc) + ', \\n')\n",
    "    lines[n_classes+2] = lines[n_classes+2].replace('\\n',str(test_f1m) + ', \\n')\n",
    "    \n",
    "    f = open('results.txt','w')\n",
    "    f.write(''.join(lines))\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.476091300Z",
     "start_time": "2025-04-08T10:55:28.476091300Z"
    }
   },
   "id": "bcb3c45e041764e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_train.close()\n",
    "dataset_val.close()\n",
    "dataset_test.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-08T10:55:28.483212800Z",
     "start_time": "2025-04-08T10:55:28.478117300Z"
    }
   },
   "id": "10eaa319e3f02f12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
